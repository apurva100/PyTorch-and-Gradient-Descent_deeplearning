{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "linear regression using pytorch built-in.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7mdAIkv_vjb"
      },
      "source": [
        "#Linear regression using pytorch built-in "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoQt0AEi_9cJ"
      },
      "source": [
        "let's begain with importing the torch.nn package from pytorch , which contains the utility classes for building neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxzIrdu2TwpV"
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2KftwS0M5QL"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HTwwMoZ_udA"
      },
      "source": [
        "as before we represented the inputs and targets and matrixs "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8twuCnqeMwBf"
      },
      "source": [
        "import numpy as np\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQIz4GWCAmdh"
      },
      "source": [
        "inputs = np.array([[73, 67, 43], \n",
        "                   [91, 88, 64], \n",
        "                   [87, 134, 58], \n",
        "                   [102, 43, 37], \n",
        "                   [69, 96, 70], \n",
        "                   [74, 66, 43], \n",
        "                   [91, 87, 65], \n",
        "                   [88, 134, 59], \n",
        "                   [101, 44, 37], \n",
        "                   [68, 96, 71], \n",
        "                   [73, 66, 44], \n",
        "                   [92, 87, 64], \n",
        "                   [87, 135, 57], \n",
        "                   [103, 43, 36], \n",
        "                   [68, 97, 70]], \n",
        "                  dtype='float32')\n",
        "\n",
        "# Targets (apples, oranges)\n",
        "targets = np.array([[56, 70], \n",
        "                    [81, 101], \n",
        "                    [119, 133], \n",
        "                    [22, 37], \n",
        "                    [103, 119],\n",
        "                    [57, 69], \n",
        "                    [80, 102], \n",
        "                    [118, 132], \n",
        "                    [21, 38], \n",
        "                    [104, 118], \n",
        "                    [57, 69], \n",
        "                    [82, 100], \n",
        "                    [118, 134], \n",
        "                    [20, 38], \n",
        "                    [102, 120]], \n",
        "                   dtype='float32')\n",
        "\n",
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mf4Y1GcXMmRt",
        "outputId": "263f2199-f6b3-48f0-f51a-eb638abb3236"
      },
      "source": [
        "inputs"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 73.,  67.,  43.],\n",
              "        [ 91.,  88.,  64.],\n",
              "        [ 87., 134.,  58.],\n",
              "        [102.,  43.,  37.],\n",
              "        [ 69.,  96.,  70.],\n",
              "        [ 74.,  66.,  43.],\n",
              "        [ 91.,  87.,  65.],\n",
              "        [ 88., 134.,  59.],\n",
              "        [101.,  44.,  37.],\n",
              "        [ 68.,  96.,  71.],\n",
              "        [ 73.,  66.,  44.],\n",
              "        [ 92.,  87.,  64.],\n",
              "        [ 87., 135.,  57.],\n",
              "        [103.,  43.,  36.],\n",
              "        [ 68.,  97.,  70.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5fGwYEIL08L"
      },
      "source": [
        "We are using 15 training examples to illustrate how to work with large datasets in small batches. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3SK0Ou2Puwv"
      },
      "source": [
        "#Dataset and DataLoader \n",
        "we'll create a tensor dataset , which allows access to rows of inputs and target as tuples and provides standard API's for working with many different types of datasets "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJ01KGdeNADI"
      },
      "source": [
        "from torch.utils.data import TensorDataset"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZV3PcO6kAc5n",
        "outputId": "09e49864-0af1-45f9-ade3-74d0636cdc19"
      },
      "source": [
        "#define dataset \n",
        "train_ds=TensorDataset(inputs,targets)\n",
        "train_ds[:3]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 73.,  67.,  43.],\n",
              "         [ 91.,  88.,  64.],\n",
              "         [ 87., 134.,  58.]]), tensor([[ 56.,  70.],\n",
              "         [ 81., 101.],\n",
              "         [119., 133.]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHj3R34xAxhs"
      },
      "source": [
        "the TensorDataset allows us to access small section of the  training data using the array indexing notation ([:3] in the above code). it returns the tuples with two elements . the 1st element contains the input variables for the selected row and the second contains the target \n",
        "\n",
        "we'll also create a dataLoader , which can split the data into batches of a predefined size while training . It also provides other utilites like surffing and random sampling of the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbq3-VHZDRJt"
      },
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stesLiOADXSg"
      },
      "source": [
        "#define dataLoader \n",
        "batch_size=5\n",
        "train_dl=DataLoader(train_ds,batch_size,shuffle=True )"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiJiESm7DzVT"
      },
      "source": [
        "we can use the dataLoader in a for loop "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeRdvA2BD5lz",
        "outputId": "8526016a-9161-4e9a-8e84-46f325eb83c2"
      },
      "source": [
        "inputs"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 73.,  67.,  43.],\n",
              "        [ 91.,  88.,  64.],\n",
              "        [ 87., 134.,  58.],\n",
              "        [102.,  43.,  37.],\n",
              "        [ 69.,  96.,  70.],\n",
              "        [ 74.,  66.,  43.],\n",
              "        [ 91.,  87.,  65.],\n",
              "        [ 88., 134.,  59.],\n",
              "        [101.,  44.,  37.],\n",
              "        [ 68.,  96.,  71.],\n",
              "        [ 73.,  66.,  44.],\n",
              "        [ 92.,  87.,  64.],\n",
              "        [ 87., 135.,  57.],\n",
              "        [103.,  43.,  36.],\n",
              "        [ 68.,  97.,  70.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNpmm9_7Ei0M",
        "outputId": "380ebea0-9d3e-435f-d58e-eacc204d31ca"
      },
      "source": [
        "for xb,yb in train_dl:\n",
        "  print(xb)\n",
        "  print(yb)\n",
        "  break"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 92.,  87.,  64.],\n",
            "        [103.,  43.,  36.],\n",
            "        [102.,  43.,  37.],\n",
            "        [101.,  44.,  37.],\n",
            "        [ 68.,  96.,  71.]])\n",
            "tensor([[ 82., 100.],\n",
            "        [ 20.,  38.],\n",
            "        [ 22.,  37.],\n",
            "        [ 21.,  38.],\n",
            "        [104., 118.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7UoMoMLE4js"
      },
      "source": [
        "by comparing the inputs with the batches (xb,yb)create above we can see that the data is shuffle (shuffle=True)\n",
        "\n",
        "in each itrration the dataloader returns one batch of data with the given batch size .If shuffle is set to True ,it shuffle the data before creating batches .Shuffling helps randamize the input to the optimization algorithum .Leading to the fast reduction in the loss \n",
        "\n",
        "the more there is randamization , the faster the model trains "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NomTU2YlGN8r"
      },
      "source": [
        "##nn.Linear \n",
        "instead of initializing the weights & baises manually , we can define the model using nn.Linear class from pyTorch , which does it automatically "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuRstYaEG3XW",
        "outputId": "bfbc0a79-8d20-4d98-dc79-4f267c515e91"
      },
      "source": [
        "#define model \n",
        "model=nn.Linear(3,2)#3=inputs(temp,rainfall,humidity)2=output(yeild of apples ,yeild of oranges )\n",
        "print(model.weight)\n",
        "print(model.bias)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0312, -0.3717,  0.0782],\n",
            "        [-0.1819, -0.0766, -0.3343]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.2450, -0.1368], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9Mr5kK3dHsB"
      },
      "source": [
        "pytorch model also have a helpfull .paremeters method , which returns a list containing all the weights and baises matrix present in the model .for our linear regression model , we have one weight matrix and one baises matrix  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ug1J785xd9aq",
        "outputId": "da3a615c-efbe-4c09-f557-78c65aa58ef6"
      },
      "source": [
        "#parameters\n",
        "list(model.parameters())"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.0312, -0.3717,  0.0782],\n",
              "         [-0.1819, -0.0766, -0.3343]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.2450, -0.1368], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CQzjke5eT3j"
      },
      "source": [
        "we can use the model to genarate pridiction in same way as before "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8LxaMyNelv4",
        "outputId": "f22191fa-33bd-4502-859f-65144457471a"
      },
      "source": [
        "#genarate pridiction \n",
        "preds=model(inputs )\n",
        "preds"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-24.0676, -32.9186],\n",
              "        [-30.7939, -44.8204],\n",
              "        [-48.2377, -45.6088],\n",
              "        [-16.5207, -34.3503],\n",
              "        [-32.6117, -43.4370],\n",
              "        [-23.7271, -33.0239],\n",
              "        [-30.3440, -45.0781],\n",
              "        [-48.1907, -46.1250],\n",
              "        [-16.8612, -34.2449],\n",
              "        [-32.5023, -43.5894],\n",
              "        [-23.6177, -33.1763],\n",
              "        [-30.4534, -44.9257],\n",
              "        [-48.6876, -45.3511],\n",
              "        [-16.6302, -34.1978],\n",
              "        [-32.9522, -43.3317]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zh5x1zC3f6kp"
      },
      "source": [
        "##Loss Function \n",
        "instead of defining loss function  manually we can use the built-in loss function \"mse_loss\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2ZKCZiZf5wk"
      },
      "source": [
        "# importing nn function \n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_LEtW902GtL"
      },
      "source": [
        "the nn.functional  package contains many usefull loss function and several other utilities   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SckxH9l02-4F"
      },
      "source": [
        "#define loss function \n",
        "loss_fn=F.mse_loss"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJUehbel65pC"
      },
      "source": [
        "let's compute the loss for the current prediction of our  model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKLB9wza7Ex4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bc0a792-b125-4dea-d146-2bfdbd489ddf"
      },
      "source": [
        "loss=loss_fn(model(inputs),targets)\n",
        "print(loss)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(16181.5654, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Yo67H5PrAN6"
      },
      "source": [
        "##optimizer\n",
        "instead of manuallly manupalating the models's weights and baises using gradiants, we can use the optimizer optim.SGD (stochastic gradiant decent ).Stochastic indicates that samples are selected in random batches instead of a single group "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5LDNXe2r6Ip"
      },
      "source": [
        "#defining optimizer\n",
        "opt=torch.optim.SGD(model.parameters(),lr=1e-5)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QB1XohH3sbm3"
      },
      "source": [
        "Note that the model.parameters() is passed as an argument to optim.SGD so that the optimizer knows which matrix to be modified during the update step .also we can specify a learning rate that contraols the amount by which the parameters are modified  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqWqNcjDt6gl"
      },
      "source": [
        "## Train the model\n",
        "we are now ready to train the model . We'll follow the same steps to implement gradiant decent \n",
        "\n",
        "*   genarate prediction\n",
        "*   calculate the loss \n",
        "*   compute gradient w.r.t weights and baises \n",
        "*   adjust the weights by substracting a small quantity proportional to gradient \n",
        "*   rest the gradient to zero \n",
        "\n",
        "the only change is that we'll work on batches of data instead of processing the entire  training data  in every itration . Let's define a utility function fit that train the model for a given number of epochs \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpXD29L71iYK"
      },
      "source": [
        "#utility function to train the model \n",
        "def fit (num_epochs, model,loss_fn,opt, train_dl):\n",
        "\n",
        "  #repeat for the given number of epochs \n",
        "  for epoch in range (num_epochs):\n",
        "\n",
        "    #train the batchs of data \n",
        "    for xb, yb in train_dl:\n",
        "\n",
        "      #1 genarate pridiction \n",
        "      pred=model(xb)\n",
        "\n",
        "      #2 calculate the loss \n",
        "      loss=loss_fn(pred,yb)\n",
        "\n",
        "      #3 compute gradiant \n",
        "      loss.backward()\n",
        "\n",
        "      #4 update parameters using gradiant \n",
        "      opt.step()\n",
        "\n",
        "      #5 reset the gradiant to zero\n",
        "      opt.zero_grad()\n",
        "\n",
        "      #6 print the progress\n",
        "      if(epoch+1)  % 10==0:\n",
        "        print(\"Epoch [{},{}] , Loss :{:.4f\", format(epoch+1), num_epochs,loss.item())\n",
        "\n",
        "\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DDWzgEXIQqh"
      },
      "source": [
        "### somethings to note above\n",
        "*   we use the data loader defined earlier to get batches of data for every itration.\n",
        "*   instead of updating parameters(weights & baises) manualy we use opt.step to perform the update and opt.zero_grad to reset the gradiant to zero\n",
        "*    we also add the log statment that prints the loss from the last batch of data for every 10th epoch to track the traning progress . loss.item retures the actual value stored in the loss tensor \n",
        "\n",
        "Let's train the model for 100 epochs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obRoKh8HKLo7",
        "outputId": "afb4811c-0a2d-4faa-fb90-590cdc74fa82"
      },
      "source": [
        "fit(100,model,loss_fn,opt,train_dl)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [{},{}] , Loss :{:.4f 10 100 575.7686157226562\n",
            "Epoch [{},{}] , Loss :{:.4f 10 100 561.189453125\n",
            "Epoch [{},{}] , Loss :{:.4f 10 100 227.7239990234375\n",
            "Epoch [{},{}] , Loss :{:.4f 20 100 191.1906280517578\n",
            "Epoch [{},{}] , Loss :{:.4f 20 100 481.578857421875\n",
            "Epoch [{},{}] , Loss :{:.4f 20 100 265.64825439453125\n",
            "Epoch [{},{}] , Loss :{:.4f 30 100 85.33868408203125\n",
            "Epoch [{},{}] , Loss :{:.4f 30 100 196.93658447265625\n",
            "Epoch [{},{}] , Loss :{:.4f 30 100 366.71490478515625\n",
            "Epoch [{},{}] , Loss :{:.4f 40 100 158.9788360595703\n",
            "Epoch [{},{}] , Loss :{:.4f 40 100 152.7715606689453\n",
            "Epoch [{},{}] , Loss :{:.4f 40 100 147.2421875\n",
            "Epoch [{},{}] , Loss :{:.4f 50 100 111.38907623291016\n",
            "Epoch [{},{}] , Loss :{:.4f 50 100 46.761436462402344\n",
            "Epoch [{},{}] , Loss :{:.4f 50 100 179.88851928710938\n",
            "Epoch [{},{}] , Loss :{:.4f 60 100 80.71263122558594\n",
            "Epoch [{},{}] , Loss :{:.4f 60 100 107.94194030761719\n",
            "Epoch [{},{}] , Loss :{:.4f 60 100 62.642967224121094\n",
            "Epoch [{},{}] , Loss :{:.4f 70 100 52.06037521362305\n",
            "Epoch [{},{}] , Loss :{:.4f 70 100 100.54353332519531\n",
            "Epoch [{},{}] , Loss :{:.4f 70 100 41.27082061767578\n",
            "Epoch [{},{}] , Loss :{:.4f 80 100 35.675174713134766\n",
            "Epoch [{},{}] , Loss :{:.4f 80 100 45.59478759765625\n",
            "Epoch [{},{}] , Loss :{:.4f 80 100 67.9670639038086\n",
            "Epoch [{},{}] , Loss :{:.4f 90 100 66.37507629394531\n",
            "Epoch [{},{}] , Loss :{:.4f 90 100 25.547138214111328\n",
            "Epoch [{},{}] , Loss :{:.4f 90 100 30.909770965576172\n",
            "Epoch [{},{}] , Loss :{:.4f 100 100 23.19875144958496\n",
            "Epoch [{},{}] , Loss :{:.4f 100 100 18.095287322998047\n",
            "Epoch [{},{}] , Loss :{:.4f 100 100 59.27203369140625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mi_-9r29Kuaq",
        "outputId": "45e95cb1-743c-4ba6-9e78-f5c967a2b7bb"
      },
      "source": [
        "preds=model(inputs)\n",
        "preds"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 58.3841,  71.9045],\n",
              "        [ 82.1250,  97.3528],\n",
              "        [116.2817, 139.0346],\n",
              "        [ 28.8183,  45.1036],\n",
              "        [ 97.2610, 108.5412],\n",
              "        [ 57.3420,  70.8867],\n",
              "        [ 81.8837,  96.7427],\n",
              "        [116.5839, 139.2927],\n",
              "        [ 29.8604,  46.1215],\n",
              "        [ 98.0618, 108.9490],\n",
              "        [ 58.1428,  71.2944],\n",
              "        [ 81.0829,  96.3349],\n",
              "        [116.5231, 139.6447],\n",
              "        [ 28.0176,  44.6958],\n",
              "        [ 98.3031, 109.5591]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vumfjLjHK5gs",
        "outputId": "b26018c7-1d23-4357-a215-a02a825acf64"
      },
      "source": [
        "targets"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.],\n",
              "        [ 57.,  69.],\n",
              "        [ 80., 102.],\n",
              "        [118., 132.],\n",
              "        [ 21.,  38.],\n",
              "        [104., 118.],\n",
              "        [ 57.,  69.],\n",
              "        [ 82., 100.],\n",
              "        [118., 134.],\n",
              "        [ 20.,  38.],\n",
              "        [102., 120.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIGi7uUJLjGd"
      },
      "source": [
        "indeed ,the prediction are close to the target. we have a trained a resonably good model to pridict crop yeild for apples and oranges by looking at the avgrage temperature , rainfall,and humidity in a reign. we can use this to make pridiction of crop yeild for new regions by passinf a batch of single row of inputs "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NqFW8sLMlPX",
        "outputId": "6b43ba28-3b84-4d43-b759-11b6da3329a7"
      },
      "source": [
        "model(torch.tensor([[75,63,44.]]))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[55.2658, 68.3156]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vd6LAgMuNDmg"
      },
      "source": [
        "the pridicted yeild of apple is 54.33 tons per hector and that of oranges is 69.30 tons per hector "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sxB_uGKNjLC"
      },
      "source": [
        "## Machine Learning vs. Classical Programming\n",
        "\n",
        " we've defined a \"model\" that assumes a specific relationship between the inputs and the outputs, expressed using some unknown parameters (weights & biases). We then show the model some know inputs and outputs and _train_ the model to come up with good values for the unknown parameters. Once trained, the model can be used to compute the outputs for new inputs.\n",
        "\n",
        "This paradigm of programming is known as _machine learning_, where we use data to figure out the relationship between inputs and outputs. _Deep learning_ is a branch of machine learning that uses matrix operations, non-linear activation functions and gradient descent to build and train models. Andrej Karpathy, the director of AI at Tesla Motors, has written a great blog post on this topics, titled [Software 2.0](https://medium.com/@karpathy/software-2-0-a64152b37c35).\n",
        "\n",
        "This picture from book [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python) by Francois Chollet captures the difference between classical programming and machine learning:\n",
        "\n",
        "![](https://i.imgur.com/oJEQe7k.png)\n",
        "\n",
        "lets make model 2 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSokLtEKNlV8"
      },
      "source": [
        "#convert machine learning model to deep learning model\n",
        "model2=nn.Sequential(nn.Linear(3,3),nn.Sigmoid(),nn.Linear(3,2))"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHkpiOG0ZXSi"
      },
      "source": [
        "opt=torch.optim.SGD(model2.parameters(),lr=1e-4)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuu83paGZ7j8",
        "outputId": "64798814-febb-44e3-a26e-8188e30d0733"
      },
      "source": [
        "fit(100,model2,F.mse_loss,opt,train_dl)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [{},{}] , Loss :{:.4f 10 100 8228.0078125\n",
            "Epoch [{},{}] , Loss :{:.4f 10 100 10363.41015625\n",
            "Epoch [{},{}] , Loss :{:.4f 10 100 6055.392578125\n",
            "Epoch [{},{}] , Loss :{:.4f 20 100 8151.2685546875\n",
            "Epoch [{},{}] , Loss :{:.4f 20 100 10260.01171875\n",
            "Epoch [{},{}] , Loss :{:.4f 20 100 5975.1845703125\n",
            "Epoch [{},{}] , Loss :{:.4f 30 100 8718.138671875\n",
            "Epoch [{},{}] , Loss :{:.4f 30 100 9707.4130859375\n",
            "Epoch [{},{}] , Loss :{:.4f 30 100 5712.47021484375\n",
            "Epoch [{},{}] , Loss :{:.4f 40 100 5072.94677734375\n",
            "Epoch [{},{}] , Loss :{:.4f 40 100 10255.255859375\n",
            "Epoch [{},{}] , Loss :{:.4f 40 100 8564.5224609375\n",
            "Epoch [{},{}] , Loss :{:.4f 50 100 5647.001953125\n",
            "Epoch [{},{}] , Loss :{:.4f 50 100 10107.3232421875\n",
            "Epoch [{},{}] , Loss :{:.4f 50 100 7895.97265625\n",
            "Epoch [{},{}] , Loss :{:.4f 60 100 5783.1943359375\n",
            "Epoch [{},{}] , Loss :{:.4f 60 100 6864.0029296875\n",
            "Epoch [{},{}] , Loss :{:.4f 60 100 10763.552734375\n",
            "Epoch [{},{}] , Loss :{:.4f 70 100 8470.3857421875\n",
            "Epoch [{},{}] , Loss :{:.4f 70 100 8433.99609375\n",
            "Epoch [{},{}] , Loss :{:.4f 70 100 6269.6279296875\n",
            "Epoch [{},{}] , Loss :{:.4f 80 100 8488.46875\n",
            "Epoch [{},{}] , Loss :{:.4f 80 100 6983.8212890625\n",
            "Epoch [{},{}] , Loss :{:.4f 80 100 7467.87255859375\n",
            "Epoch [{},{}] , Loss :{:.4f 90 100 9691.224609375\n",
            "Epoch [{},{}] , Loss :{:.4f 90 100 6203.1328125\n",
            "Epoch [{},{}] , Loss :{:.4f 90 100 6814.82666015625\n",
            "Epoch [{},{}] , Loss :{:.4f 100 100 3940.916748046875\n",
            "Epoch [{},{}] , Loss :{:.4f 100 100 7514.4951171875\n",
            "Epoch [{},{}] , Loss :{:.4f 100 100 11025.603515625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Fg3x9o8a-a6"
      },
      "source": [
        "## Introduction to Machine Learning\n",
        "\n",
        "<img src=\"https://i.imgur.com/oJEQe7k.png\" width=\"480\" />\n",
        "\n",
        "<div style=\"text-align:center;\">\n",
        "    <a href=\"https://www.manning.com/books/deep-learning-with-python\">Image Source</a>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75EttqSZbDl1"
      },
      "source": [
        "### Linear Regression\n",
        "\n",
        "#### Linear Regression Data\n",
        "\n",
        "<img src=\"https://i.imgur.com/mtkR2lB.png\" width=\"540\" >\n",
        "\n",
        "#### Linear Regression Visualization\n",
        "\n",
        "<img src=\"https://i.imgur.com/mtkR2lB.png\" width=\"480\">\n",
        "\n",
        "\n",
        "#### Linear Regression model\n",
        "\n",
        "$$\n",
        "\\hspace{2.5cm} X \\hspace{1.1cm} \\times \\hspace{1.2cm} W^T \\hspace{1.2cm}  + \\hspace{1cm} b \\hspace{2cm}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\left[ \\begin{array}{cc}\n",
        "73 & 67 & 43 \\\\\n",
        "91 & 88 & 64 \\\\\n",
        "\\vdots & \\vdots & \\vdots \\\\\n",
        "69 & 96 & 70\n",
        "\\end{array} \\right]\n",
        "%\n",
        "\\times\n",
        "%\n",
        "\\left[ \\begin{array}{cc}\n",
        "w_{11} & w_{21} \\\\\n",
        "w_{12} & w_{22} \\\\\n",
        "w_{13} & w_{23}\n",
        "\\end{array} \\right]\n",
        "%\n",
        "+\n",
        "%\n",
        "\\left[ \\begin{array}{cc}\n",
        "b_{1} & b_{2} \\\\\n",
        "b_{1} & b_{2} \\\\\n",
        "\\vdots & \\vdots \\\\\n",
        "b_{1} & b_{2} \\\\\n",
        "\\end{array} \\right]\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1eLDB1AbMf5"
      },
      "source": [
        "### Feedfoward Neural Network\n",
        "\n",
        "![ffnn](https://upload.wikimedia.org/wikipedia/commons/thumb/0/00/Multi-Layer_Neural_Network-Vector-Blank.svg/400px-Multi-Layer_Neural_Network-Vector-Blank.svg.png)\n",
        "\n",
        "Conceptually, you think of feedforward neural networks as two or more linear regression models stacked on top of one another with a non-linear activation function applied between them.\n",
        "\n",
        "<img src=\"https://cdn-images-1.medium.com/max/1600/1*XxxiA0jJvPrHEJHD4z893g.png\" width=\"640\">\n",
        "\n",
        "To use a feedforward neural network instead of linear regression, we can extend the `nn.Module` class from PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFJvSKUZbP1b"
      },
      "source": [
        ""
      ]
    }
  ]
}
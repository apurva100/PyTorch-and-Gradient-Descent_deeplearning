{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_deeplearning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Asa832e2-OTH"
      },
      "source": [
        "#PyTorch  and Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihW-ML-s-ZRo"
      },
      "source": [
        "import  torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKWss45R-pgh"
      },
      "source": [
        "##Tensor\n",
        "PyTorch is a library for processing tensor  . Tensor is a number , matrix,vector or any n-dimension array.  Lets create a tensor with a single number "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RO-cUWiq-fOp",
        "outputId": "116e6654-b0ff-4063-cb3b-ccdf7b18644d"
      },
      "source": [
        "t1=torch.tensor(4.)\n",
        "t1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7jEFF3T_lhX"
      },
      "source": [
        " 4. is a shorthand for 4.0 .It is used to indicate to  python that we  want floating point atribute  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP_C_qK-ACCF",
        "outputId": "80946c03-9cbe-4757-e858-b45795ee2d47"
      },
      "source": [
        "t1.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xLB9u9mAS6r"
      },
      "source": [
        "let's try more complex  tensors\n",
        "(all  the values in a tensor are of the same data type)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HI6o70mAYxf",
        "outputId": "fc3ef2cf-3b93-4c01-8f5f-031e9fb605e0"
      },
      "source": [
        "#vector(1-d tensor)\n",
        "t2=torch.tensor([1.,2,3,4])\n",
        "t2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3., 4.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFjwlfq2BGRc",
        "outputId": "e6844621-88b1-48d9-bbe9-3f0977c3f026"
      },
      "source": [
        "#matrix\n",
        "t3=torch.tensor([[2.,3],[3,4],[5,3]])\n",
        "t3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 3.],\n",
              "        [3., 4.],\n",
              "        [5., 3.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHVeYX8FBb2o",
        "outputId": "d3f14300-1c55-44ed-cdac-1dd895f1dc05"
      },
      "source": [
        "#3-D matrix\n",
        "t4=torch.tensor([\n",
        "                 [[1,2],[2,3]],\n",
        "                 [[2,3],[4,5]]\n",
        "                 ])\n",
        "t4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 2],\n",
              "         [2, 3]],\n",
              "\n",
              "        [[2, 3],\n",
              "         [4, 5]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHDOljTgCrMH"
      },
      "source": [
        "tensor  can have any number of dimensions and different lenght anong each dimension . we can expect the length along each dimension of a tensor using  .shape property"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ch8EhS35DXCR",
        "outputId": "c7e6e8bd-0d1f-4687-f553-b0f4cdaaf2a3"
      },
      "source": [
        "t1.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGyfyfvjDham",
        "outputId": "09a670e5-5441-4a82-fb9b-c6ef15c027f3"
      },
      "source": [
        "t2.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAB0kmnYDlNR",
        "outputId": "11799bfa-ef18-4221-8a42-5558a3b97e8e"
      },
      "source": [
        "t3.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsl64mcgDnBj",
        "outputId": "14562d22-5206-4cdd-8379-295d4803accb"
      },
      "source": [
        "t4.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_6tD8uhD3ol"
      },
      "source": [
        "Note that it's not possible to create tensors with an improper shape."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90mOm-1FD67B"
      },
      "source": [
        "##t5=torch.tensor([[1,2,3],[1,2]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tm9qeGkZEv8a"
      },
      "source": [
        "A `ValueError` is thrown because the lengths of the rows `[1,2,3]` and `[1, 2]` don't match."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ev-JZLrFVnW"
      },
      "source": [
        "##Tensor operations and gradiants \n",
        "we can combine tensor with usaual arithematic operations\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OkIKRIyETx7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2231d835-4d37-4c33-edb6-db4a6f9d96fd"
      },
      "source": [
        "x=torch.tensor(3.)\n",
        "w=torch.tensor(4.,requires_grad=True)\n",
        "b=torch.tensor(5.,requires_grad=True)\n",
        "x,w,b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(3.), tensor(4., requires_grad=True), tensor(5., requires_grad=True))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GggiISmqG4WB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4507882f-67fe-4853-aa1a-3d0c78a24377"
      },
      "source": [
        "#arithematic operations\n",
        "y=w*x+b\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(17., grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5CgXWj9HKl5"
      },
      "source": [
        "as axpected y value is 17 , so what makes pytorch (requires_grade) unique is that  we can automatically compute derivative of y w.r.t the tensor whose requires_grade are set to True.This feature is called automatic gradient.\n",
        "(dy/dw=0,dy/db=1)\n",
        "\n",
        "- to compute the derivatives, we can invoke .backward method on your result y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyrXCRFeH6Rs"
      },
      "source": [
        "y.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr-U9ClUJLP9"
      },
      "source": [
        "the derivatves of y w.r.t the input  tensor are stored in .grad property of the respective tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7CCBFjzJiCC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d73c346-286a-4d65-9b90-75277a2f9301"
      },
      "source": [
        "print('dy/dx',x.grad)\n",
        "print('dy/dw',w.grad)\n",
        "print('dy/db',b.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dy/dx None\n",
            "dy/dw tensor(3.)\n",
            "dy/db tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QifXqZcyKMbX"
      },
      "source": [
        "As expected, `dy/dw` has the same value as `x`, i.e., `3`, and `dy/db` has the value `1`. Note that `x.grad` is `None` because `x` doesn't have `requires_grad` set to `True`. \n",
        "\n",
        "The \"grad\" in `w.grad` is short for _gradient_, which is another term for derivative. The term _gradient_ is primarily used while dealing with vectors and matrices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdGRtlYb7V-g"
      },
      "source": [
        "##Tensor Functions \n",
        "apart from arithematic operations ,the tourch module contain many number of functons   for creating and manupalating tensors .Let's look at some eg "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFKDLcZ674yE",
        "outputId": "9aee2d09-8b5f-4ffb-b4c8-f5cca37f6aeb"
      },
      "source": [
        "#creating a tensor with fixed values for every element \n",
        "t6=torch.full((3,2),42)\n",
        "t6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[42, 42],\n",
              "        [42, 42],\n",
              "        [42, 42]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHsTe80aKScE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c1d318b-1129-448a-91bb-d3c83893e2df"
      },
      "source": [
        "#concatenating two tensor of compatable shape\n",
        "t7=torch.cat((t3,t6))\n",
        "t7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.,  3.],\n",
              "        [ 3.,  4.],\n",
              "        [ 5.,  3.],\n",
              "        [42., 42.],\n",
              "        [42., 42.],\n",
              "        [42., 42.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkY7WrmW85_P",
        "outputId": "ea07e165-da51-4e25-e902-e894489a25ca"
      },
      "source": [
        "#computing the sin of each element\n",
        "t8=torch.sin(t7)\n",
        "t8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.9093,  0.1411],\n",
              "        [ 0.1411, -0.7568],\n",
              "        [-0.9589,  0.1411],\n",
              "        [-0.9165, -0.9165],\n",
              "        [-0.9165, -0.9165],\n",
              "        [-0.9165, -0.9165]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zd9eRqZN9FaC",
        "outputId": "985675fd-d0b8-4c07-a07b-200513a1e839"
      },
      "source": [
        "#changing the shape of tensor\n",
        "t9=t8.reshape(3,2,2)\n",
        "t9"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.9093,  0.1411],\n",
              "         [ 0.1411, -0.7568]],\n",
              "\n",
              "        [[-0.9589,  0.1411],\n",
              "         [-0.9165, -0.9165]],\n",
              "\n",
              "        [[-0.9165, -0.9165],\n",
              "         [-0.9165, -0.9165]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-5o676SAMr6"
      },
      "source": [
        "## Interoperability with Numpy\n",
        "\n",
        "[Numpy](http://www.numpy.org/) is a popular open-source library used for mathematical and scientific computing in Python. It enables efficient operations on large multi-dimensional arrays and has a vast ecosystem of supporting libraries, including:\n",
        "\n",
        "* [Pandas](https://pandas.pydata.org/) for file I/O and data analysis\n",
        "* [Matplotlib](https://matplotlib.org/) for plotting and visualization\n",
        "* [OpenCV](https://opencv.org/) for image and video processing\n",
        "\n",
        "\n",
        "Instead of reinventing the wheel, PyTorch interoperates well with Numpy to leverage its existing ecosystem of tools and libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vssLa9b49FLz",
        "outputId": "2b29bce5-ccf1-43d7-b7e2-56c062eb7ca8"
      },
      "source": [
        "import numpy as np\n",
        "x=np.array([[1,2],[2,3]])\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2],\n",
              "       [2, 3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQkoT323DNIi"
      },
      "source": [
        "we can convert numpy array to pytroch tensor using torch.from_numpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GV0z8NN9E80",
        "outputId": "739b8067-7b3d-4f48-b623-2275bb2758d6"
      },
      "source": [
        "y=torch.from_numpy(x)\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [2, 3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2n4WwWNAGhJT",
        "outputId": "9e57c247-e7d1-4fe7-8097-33488ade973e"
      },
      "source": [
        "x.dtype, y.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dtype('int64'), torch.int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BoL84miHAsG"
      },
      "source": [
        "##we can convert pytorch to numpy array using .numpy method"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1hNtUtTHNNB",
        "outputId": "f1f6408b-8d77-44d7-c112-2f416ea7c8c1"
      },
      "source": [
        "z=y.numpy()\n",
        "z"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2],\n",
              "       [2, 3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOSndN_AIGHg"
      },
      "source": [
        "The interoperability between PyTorch and Numpy is essential because most datasets you'll work with will likely be read and preprocessed as Numpy arrays.\n",
        "\n",
        "You might wonder why we need a library like PyTorch at all since Numpy already provides data structures and utilities for working with multi-dimensional numeric data. There are two main reasons:\n",
        "\n",
        "1. **Autograd**: The ability to automatically compute gradients for tensor operations is essential for training deep learning models.\n",
        "2. **GPU support**: While working with massive datasets and large models, PyTorch tensor operations can be performed efficiently using a Graphics Processing Unit (GPU). Computations that might typically take hours can be completed within minutes using GPUs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1u-O5ZdKDTz"
      },
      "source": [
        "#Gradiant desent and Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsWiklwcNJ9Y"
      },
      "source": [
        "## Introduction to Linear Regression\n",
        "\n",
        "In this tutorial, we'll discuss one of the foundational algorithms in machine learning: *Linear regression*. We'll create a model that predicts crop yields for apples and oranges (*target variables*) by looking at the average temperature, rainfall, and humidity (*input variables or features*) in a region. Here's the training data:\n",
        "\n",
        "![linear-regression-training-data](https://i.imgur.com/6Ujttb4.png)\n",
        "\n",
        "In a linear regression model, each target variable is estimated to be a weighted sum of the input variables, offset by some constant, known as a bias :\n",
        "\n",
        "```\n",
        "yield_apple  = w11 * temp + w12 * rainfall + w13 * humidity + b1\n",
        "yield_orange = w21 * temp + w22 * rainfall + w23 * humidity + b2\n",
        "```\n",
        "\n",
        "Visually, it means that the yield of apples is a linear or planar function of temperature, rainfall and humidity:\n",
        "\n",
        "![linear-regression-graph](https://i.imgur.com/4DJ9f8X.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKGgIIyBNSMN"
      },
      "source": [
        "The *learning* part of linear regression is to figure out a set of weights `w11, w12,... w23, b1 & b2` using the training data, to make accurate predictions for new data. The _learned_ weights will be used to predict the yields for apples and oranges in a new region using the average temperature, rainfall, and humidity for that region. \n",
        "\n",
        "We'll _train_ our model by adjusting the weights slightly many times to make better predictions, using an optimization technique called *gradient descent*. Let's begin by importing Numpy and PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxZghInHNJOY"
      },
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8NFKH7EOP04"
      },
      "source": [
        "## Training data\n",
        "\n",
        "We can represent the training data using two matrices: `inputs` and `targets`, each with one row per observation, and one column per variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3Lo7HwIKBVp"
      },
      "source": [
        "#input (temp,rainfall, humidity)\n",
        "inputs=np.array([[73, 67, 43], \n",
        "                   [91, 88, 64], \n",
        "                   [87, 134, 58], \n",
        "                   [102, 43, 37], \n",
        "                   [69, 96, 70]], dtype='float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkspSg63PI_x"
      },
      "source": [
        "# Targets (apples, oranges)\n",
        "targets = np.array([[56, 70], \n",
        "                    [81, 101], \n",
        "                    [119, 133], \n",
        "                    [22, 37], \n",
        "                    [103, 119]], dtype='float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgQhKE8PYLxZ"
      },
      "source": [
        "we create  separate  input and target values ,as we'll operate on them seperately . Also we have created numpy array as we have to load /read the csv files and do some processing and then we'll convert it to pytorch  tensor "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARkVh-uBY3hM",
        "outputId": "5d881c34-ca0a-40f5-9b84-fbda0cf79851"
      },
      "source": [
        "#convert input and target to tensor \n",
        "inputs=torch.from_numpy(inputs)\n",
        "targets=torch.from_numpy(targets)\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]])\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__Rc-Xh6mAxd"
      },
      "source": [
        "##Linear regression Model from scratch\n",
        "the wieghts and baises(w1,w2,w3.........b1 &b2) can also be represented as matrix ,initialized as random values. The first row of w and 1st element of b are used to pridect the 1st target variables i.e yeild of apples and oranges "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAte5-AkY4Fc",
        "outputId": "280cd16e-75ce-4052-a679-62d0de4f10ef"
      },
      "source": [
        "w=torch.randn(2,3,requires_grad=True )#2 row and 3 column matrix\n",
        "b=torch.randn(2,requires_grad=True)# biases b1,b2 form a vector\n",
        "print(w)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.6509,  0.5736,  0.7497],\n",
            "        [-1.1475, -0.2892,  0.3951]], requires_grad=True)\n",
            "tensor([-0.1231,  1.0086], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoX1InoPpRyO"
      },
      "source": [
        "`torch.randn` creates a tensor with the given shape, with elements picked randomly from a [normal distribution](https://en.wikipedia.org/wiki/Normal_distribution) with mean 0 and standard deviation 1.\n",
        "\n",
        "Our *model* is simply a function that performs a matrix multiplication of the `inputs` and the weights `w` (transposed) and adds the bias `b` (replicated for each observation).\n",
        "\n",
        "![matrix-mult](https://i.imgur.com/WGXLFvA.png)\n",
        "\n",
        "We can define the model as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXa8_--mqVAC",
        "outputId": "6cf06258-f43c-48d1-e9e6-064934753f47"
      },
      "source": [
        "inputs #temp,rainfall,humidity"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 73.,  67.,  43.],\n",
              "        [ 91.,  88.,  64.],\n",
              "        [ 87., 134.,  58.],\n",
              "        [102.,  43.,  37.],\n",
              "        [ 69.,  96.,  70.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1HaLkjWqimb",
        "outputId": "be324346-8b6e-4431-caae-d771984550e7"
      },
      "source": [
        "#for matrix multiplcation in pytroch we use @  and for transpose of matrix we use .t()\n",
        "inputs @ w.t() + b             #  mx+c (m=inputs,x=w,c=b)  ,,, this will produ"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  23.0273,  -85.1475],\n",
              "        [  39.0996, -103.5787],\n",
              "        [  63.5911, -114.6638],\n",
              "        [ -14.1139, -113.8550],\n",
              "        [  62.5067,  -78.2763]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8XMwQVRuI0X"
      },
      "source": [
        "def model(x):\n",
        "  return x @ w.t() +b # here have created a function (model) which takes the input (x) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHJty2itt21H"
      },
      "source": [
        "`@` represents matrix multiplication in PyTorch, and the `.t` method returns the transpose of a tensor.\n",
        "\n",
        "The matrix obtained by passing the input data into the model is a set of predictions for the target variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7t6uXYkum4_",
        "outputId": "94d406f1-564a-4f33-85bc-10495671071b"
      },
      "source": [
        "#genarate pridictions \n",
        "preds= model(inputs)\n",
        "print(preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[  23.0273,  -85.1475],\n",
            "        [  39.0996, -103.5787],\n",
            "        [  63.5911, -114.6638],\n",
            "        [ -14.1139, -113.8550],\n",
            "        [  62.5067,  -78.2763]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYpRVeygu_NL"
      },
      "source": [
        "Let's compare the predictions of our model with the actual targets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8TFrsaZvCj6",
        "outputId": "c183cedb-0644-4a53-d7d8-c4601c815381"
      },
      "source": [
        "#compare with targets\n",
        "print(targets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZiBPJ0WvYfU"
      },
      "source": [
        "You can see a big difference between our model's predictions and the actual targets because we've initialized our model with random weights and biases. Obviously, we can't expect a randomly initialized model to *just work*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q35t-zHbwV9U",
        "outputId": "05d7f66d-d78b-4902-d03d-e3b28c8b68d4"
      },
      "source": [
        "diff=preds-targets \n",
        "diff #as there are some -ve values so wi'll take  the square of it(diff *diff) and find its average \n",
        "#to  find find avg we do the sum( torch.sum()) and divide it it total numbber of values of the given matrix(.numel())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ -32.9727, -155.1476],\n",
              "        [ -41.9004, -204.5787],\n",
              "        [ -55.4089, -247.6638],\n",
              "        [ -36.1139, -150.8550],\n",
              "        [ -40.4933, -197.2763]], grad_fn=<SubBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tj4E4CCkxdHE",
        "outputId": "cbe06cf0-2693-4b26-d4ed-0b2dcea92a83"
      },
      "source": [
        "torch.sum(diff*diff) / diff.numel() # this number tells us  that how bad is our model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(19779.2695, grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRig9QSm0BX0"
      },
      "source": [
        "## Loss function\n",
        "\n",
        "Before we improve our model, we need a way to evaluate how well our model is performing. We can compare the model's predictions with the actual targets using the following method:\n",
        "\n",
        "* Calculate the difference between the two matrices (`preds` and `targets`).\n",
        "* Square all elements of the difference matrix to remove negative values.\n",
        "* Calculate the average of the elements in the resulting matrix.\n",
        "\n",
        "The result is a single number, known as the **mean squared error** (MSE)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-rToxiH2615"
      },
      "source": [
        "#MSE  loss\n",
        "def mse(t1,t2):\n",
        "  diff=t1-t2\n",
        "  return torch.sum(diff*diff) / diff.numel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBlSBtMq76zn"
      },
      "source": [
        "`torch.sum` returns the sum of all the elements in a tensor. The `.numel` method of a tensor returns the number of elements in a tensor. Let's compute the mean squared error for the current predictions of our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7k65k5xA77u0",
        "outputId": "af005fb2-2314-4951-8087-bf0a7da257c6"
      },
      "source": [
        "#compute loss\n",
        "loss= mse(preds,targets)\n",
        "print(loss)# the lower thw loss the better the  model "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(19779.2695, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JUhorTI_tTs"
      },
      "source": [
        "#compute gradiant \n",
        "loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADo0qlD__5cB"
      },
      "source": [
        "the gradiant is stored in .grad property of the respective tensor. Note that  the derivative of loss w.r.t the weights matrix is itself a matrix with the same dimension  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu3KXlugAru_",
        "outputId": "e0dee3b9-71f5-496d-fbe8-5f836bd1e017"
      },
      "source": [
        "#graident for weights \n",
        "print(w)\n",
        "print(w.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.6509,  0.5736,  0.7497],\n",
            "        [-1.1475, -0.2892,  0.3951]], requires_grad=True)\n",
            "tensor([[ -3503.6367,  -3752.2927,  -2296.7837],\n",
            "        [-16097.6943, -17402.0117, -10703.9727]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgN2Sjh_ChUR",
        "outputId": "fa002a3f-7ad5-43f6-a3cd-e1c3e0fa8508"
      },
      "source": [
        "print(b)\n",
        "print(b.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.1231,  1.0086], requires_grad=True)\n",
            "tensor([ -41.3779, -191.1043])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kskHR4W_Bmm3"
      },
      "source": [
        "## Adjust weights and biases to reduce the loss\n",
        "\n",
        "The loss is a [quadratic function](https://en.wikipedia.org/wiki/Quadratic_function) of our weights and biases, and our objective is to find the set of weights where the loss is the lowest. If we plot a graph of the loss w.r.t any individual weight or bias element, it will look like the figure shown below. An important insight from calculus is that the gradient indicates the rate of change of the loss, i.e., the loss function's [slope](https://en.wikipedia.org/wiki/Slope) w.r.t. the weights and biases.\n",
        "\n",
        "If a gradient element is **positive**:\n",
        "\n",
        "* **increasing** the weight element's value slightly will **increase** the loss\n",
        "* **decreasing** the weight element's value slightly will **decrease** the loss\n",
        "\n",
        "![postive-gradient](https://i.imgur.com/WLzJ4xP.png)\n",
        "\n",
        "If a gradient element is **negative**:\n",
        "\n",
        "* **increasing** the weight element's value slightly will **decrease** the loss\n",
        "* **decreasing** the weight element's value slightly will **increase** the loss\n",
        "\n",
        "![negative=gradient](https://i.imgur.com/dvG2fxU.png)\n",
        "\n",
        "The increase or decrease in the loss by changing a weight element is proportional to the gradient of the loss w.r.t. that element. This observation forms the basis of _the gradient descent_ optimization algorithm that we'll use to improve our model (by _descending_ along the _gradient_).\n",
        "\n",
        "We can subtract from each weight element a small quantity proportional to the derivative of the loss w.r.t. that element to reduce the loss slightly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zrCAXb8BmRr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adc96b68-3dc8-42c7-e16a-3582bac5ca8a"
      },
      "source": [
        "print(w)\n",
        "w.grad\n",
        "w-w.grad*1e-5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.6509,  0.5736,  0.7497],\n",
            "        [-1.1475, -0.2892,  0.3951]], requires_grad=True)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.6159,  0.6111,  0.7726],\n",
              "        [-0.9865, -0.1152,  0.5022]], grad_fn=<SubBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScHp-g2Lb6pc"
      },
      "source": [
        "with torch.no_grad():\n",
        "  w-=w.grad * 1e-5\n",
        "  b-=b.grad * 1e-5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlXSnHyJY7Xa"
      },
      "source": [
        "we multiply gradiant with a  very small number(10^5 in this case) .to ensure that we don't modify the weight by a very large amount . we want to take a small step in the downhill direction of the graident ,not a gaint leap.this number is call the learning rate of algorithum.\n",
        "\n",
        "we use torch.no_grad() to indicate to pytorch that we shoud'nt track,calculate or modify the graident while updating the weights and baises "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecWf-_Ric938",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25789584-0eb4-4a7c-85ff-6ff310212602"
      },
      "source": [
        "w,b # new weights and baises \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.6159,  0.6111,  0.7726],\n",
              "         [-0.9865, -0.1152,  0.5022]], requires_grad=True),\n",
              " tensor([-0.1226,  1.0105], requires_grad=True))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra6sv9xFa4C9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69b0d6a6-a021-49f3-956d-d9d2d1ad2442"
      },
      "source": [
        "#let's verify the loss is actually lower\n",
        "preds=model(inputs)\n",
        "loss= mse(preds,targets)\n",
        "print(loss)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(13331.3496, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3ZH9CLT-9PJ"
      },
      "source": [
        "before the loss  was 19779.2695 and now it is 13331.3496 ... there is so much decrease .. and that's preety good \n",
        "\n",
        "\n",
        "befoe we proceed. we rest the gradiantb to zero by invoking .zero() method. we need to do this because pytorch accumulates gradiants . otherwise the next if we invoke .backward on the loss , the new gradiant value is added to the existing gradiant , which will lead to unexpected results "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4XVpIB0-8y8",
        "outputId": "a25ae24c-c83e-4c84-ec00-e7775bd6cdbd"
      },
      "source": [
        "w.grad.zero_()\n",
        "b.grad.zero_()\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifFUAS8fBFZ8"
      },
      "source": [
        "#Train the model using gradiant decent \n",
        "as we saw above we reduse the loss and improve our model using the gradiant desent optimization algorithum .\n",
        "thus we can train our model using following steps :\n",
        "\n",
        "\n",
        "1.   Generate pridiction \n",
        "2.   Calculate the loss\n",
        "3.   compute gradiant w.r.t. weights and baises \n",
        "4.   adjust the weights by substracting a smallquantity proportional to the gradiant \n",
        "5. rest the gradiant to zero\n",
        "\n",
        "lets implement the above steps \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bONOew1ua33Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5c174fe-caab-422a-ae05-1d1f3cbd1163"
      },
      "source": [
        "# generate pridictions\n",
        "preds=model(inputs)\n",
        "preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 29.0870, -57.1323],\n",
              "        [ 47.0603, -66.7636],\n",
              "        [ 72.9998, -71.1299],\n",
              "        [ -8.0765, -85.9902],\n",
              "        [ 70.1346, -42.9682]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syUn3lySa3pE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd590d27-c096-4c56-d21f-fb2ad84e6297"
      },
      "source": [
        "#Calculate the loss\n",
        "loss=mse(preds,targets)\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(13331.3496, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LQ9tngJa3Yx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88c332c3-5455-47fa-d931-bf45f2a6c84d"
      },
      "source": [
        "#compute gradiant w.r.t. weights and baises\n",
        "loss.backward()\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ -2878.1399,  -3080.4521,  -1882.1649],\n",
            "        [-13205.4492, -14294.3984,  -8786.3008]])\n",
            "tensor([ -33.9590, -156.7968])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Opv4yf7HEXdL"
      },
      "source": [
        "lets update the weights and baises using the gradiant computed above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdteWcqLEmvb"
      },
      "source": [
        "#adjust the weights by substracting a smallquantity proportional to the gradiant\n",
        "with torch.no_grad():\n",
        "  w-=w.grad* 1e-5\n",
        "  b-=b.grad* 1e-5\n",
        "  w.grad.zero_()\n",
        "  b.grad.zero_()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_s-fX0f9F_6J"
      },
      "source": [
        "lets take a look at new weights and baises "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "If7duZZfFd2n",
        "outputId": "54dc4771-aefe-4e85-ece2-758bcfd68087"
      },
      "source": [
        "print(w)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.5871,  0.6419,  0.7915],\n",
            "        [-0.8545,  0.0277,  0.5900]], requires_grad=True)\n",
            "tensor([-0.1223,  1.0120], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hiZMXS7GWUw"
      },
      "source": [
        "with new weights and baises , the model should have lower loss "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2kG7T1dGVw_",
        "outputId": "35072547-16f7-4829-fb85-03fb271be8ef"
      },
      "source": [
        "#calculate loss\n",
        "preds=model(inputs)\n",
        "loss=mse(preds,targets)\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(8986.1738, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb3mXucxG1e-"
      },
      "source": [
        "we have reached a significant reduction in the loss merly by adjusting the weights and baises slightly using gradiant decent "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vjw_jPabLHQO"
      },
      "source": [
        "#Train for multiple epochs \n",
        "to reduse the loss further, we can repate the process of adjusting the weights and baises using gradiant decent multiple times. Each itrration is called epoch. Let's train the model 100 times "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wgj8QlEKL3nO"
      },
      "source": [
        "for i in range(500):\n",
        "  preds=model(inputs)\n",
        "  loss=mse(preds,targets)\n",
        "  loss.backward\n",
        "  with torch.no_grad():\n",
        "    w-=w.grad *1e-5\n",
        "    b-=b.grad *1e-5\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pjxSx4vNUoF"
      },
      "source": [
        "lets verify the loss is now lower"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAzYgsChNRuV",
        "outputId": "6e10ca7d-3b79-43b6-e3b7-5b4ad4ba6a2e"
      },
      "source": [
        "#calculate loss\n",
        "preds=model(inputs)\n",
        "loss=mse(preds,targets)\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(8986.1738, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2zHhWJnTWST",
        "outputId": "70a098b3-8db6-4cea-cff9-529e8e36e464"
      },
      "source": [
        "preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 34.0616, -34.1354],\n",
              "        [ 53.5951, -36.5428],\n",
              "        [ 80.7236, -35.3890],\n",
              "        [ -3.1195, -63.1215],\n",
              "        [ 76.3956, -13.9819]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sl0GXKYHTYXt",
        "outputId": "a1ded7ef-5bbd-47ae-b085-f06bfaaa5c5b"
      },
      "source": [
        "targets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwoUHafN8cgY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
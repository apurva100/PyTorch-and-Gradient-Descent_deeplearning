{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "linear regression using pytorch built-in.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7mdAIkv_vjb"
      },
      "source": [
        "#Linear regression using pytorch built-in "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoQt0AEi_9cJ"
      },
      "source": [
        "let's begain with importing the torch.nn package from pytorch , which contains the utility classes for building neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxzIrdu2TwpV"
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2KftwS0M5QL"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HTwwMoZ_udA"
      },
      "source": [
        "as before we represented the inputs and targets and matrixs "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8twuCnqeMwBf"
      },
      "source": [
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQIz4GWCAmdh"
      },
      "source": [
        "inputs = np.array([[73, 67, 43], \n",
        "                   [91, 88, 64], \n",
        "                   [87, 134, 58], \n",
        "                   [102, 43, 37], \n",
        "                   [69, 96, 70], \n",
        "                   [74, 66, 43], \n",
        "                   [91, 87, 65], \n",
        "                   [88, 134, 59], \n",
        "                   [101, 44, 37], \n",
        "                   [68, 96, 71], \n",
        "                   [73, 66, 44], \n",
        "                   [92, 87, 64], \n",
        "                   [87, 135, 57], \n",
        "                   [103, 43, 36], \n",
        "                   [68, 97, 70]], \n",
        "                  dtype='float32')\n",
        "\n",
        "# Targets (apples, oranges)\n",
        "targets = np.array([[56, 70], \n",
        "                    [81, 101], \n",
        "                    [119, 133], \n",
        "                    [22, 37], \n",
        "                    [103, 119],\n",
        "                    [57, 69], \n",
        "                    [80, 102], \n",
        "                    [118, 132], \n",
        "                    [21, 38], \n",
        "                    [104, 118], \n",
        "                    [57, 69], \n",
        "                    [82, 100], \n",
        "                    [118, 134], \n",
        "                    [20, 38], \n",
        "                    [102, 120]], \n",
        "                   dtype='float32')\n",
        "\n",
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mf4Y1GcXMmRt",
        "outputId": "ba449ccf-840b-43a2-83ee-774f4c0c5c70"
      },
      "source": [
        "inputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 73.,  67.,  43.],\n",
              "        [ 91.,  88.,  64.],\n",
              "        [ 87., 134.,  58.],\n",
              "        [102.,  43.,  37.],\n",
              "        [ 69.,  96.,  70.],\n",
              "        [ 74.,  66.,  43.],\n",
              "        [ 91.,  87.,  65.],\n",
              "        [ 88., 134.,  59.],\n",
              "        [101.,  44.,  37.],\n",
              "        [ 68.,  96.,  71.],\n",
              "        [ 73.,  66.,  44.],\n",
              "        [ 92.,  87.,  64.],\n",
              "        [ 87., 135.,  57.],\n",
              "        [103.,  43.,  36.],\n",
              "        [ 68.,  97.,  70.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5fGwYEIL08L"
      },
      "source": [
        "We are using 15 training examples to illustrate how to work with large datasets in small batches. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3SK0Ou2Puwv"
      },
      "source": [
        "#Dataset and DataLoader \n",
        "we'll create a tensor dataset , which allows access to rows of inputs and target as tuples and provides standard API's for working with many different types of datasets "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJ01KGdeNADI"
      },
      "source": [
        "from torch.utils.data import TensorDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZV3PcO6kAc5n",
        "outputId": "84040342-f374-47b1-f033-0ed6c408896b"
      },
      "source": [
        "#define dataset \n",
        "train_ds=TensorDataset(inputs,targets)\n",
        "train_ds[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 73.,  67.,  43.],\n",
              "         [ 91.,  88.,  64.],\n",
              "         [ 87., 134.,  58.]]), tensor([[ 56.,  70.],\n",
              "         [ 81., 101.],\n",
              "         [119., 133.]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHj3R34xAxhs"
      },
      "source": [
        "the TensorDataset allows us to access small section of the  training data using the array indexing notation ([:3] in the above code). it returns the tuples with two elements . the 1st element contains the input variables for the selected row and the second contains the target \n",
        "\n",
        "we'll also create a dataLoader , which can split the data into batches of a predefined size while training . It also provides other utilites like surffing and random sampling of the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbq3-VHZDRJt"
      },
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stesLiOADXSg"
      },
      "source": [
        "#define dataLoader \n",
        "batch_size=5\n",
        "train_dl=DataLoader(train_ds,batch_size,shuffle=True )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiJiESm7DzVT"
      },
      "source": [
        "we can use the dataLoader in a for loop "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeRdvA2BD5lz",
        "outputId": "34f0f334-d884-407a-b011-5955a5ca89e9"
      },
      "source": [
        "inputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 73.,  67.,  43.],\n",
              "        [ 91.,  88.,  64.],\n",
              "        [ 87., 134.,  58.],\n",
              "        [102.,  43.,  37.],\n",
              "        [ 69.,  96.,  70.],\n",
              "        [ 74.,  66.,  43.],\n",
              "        [ 91.,  87.,  65.],\n",
              "        [ 88., 134.,  59.],\n",
              "        [101.,  44.,  37.],\n",
              "        [ 68.,  96.,  71.],\n",
              "        [ 73.,  66.,  44.],\n",
              "        [ 92.,  87.,  64.],\n",
              "        [ 87., 135.,  57.],\n",
              "        [103.,  43.,  36.],\n",
              "        [ 68.,  97.,  70.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNpmm9_7Ei0M",
        "outputId": "f74c186d-cbc5-4ab6-f861-cce8534e480c"
      },
      "source": [
        "for xb,yb in train_dl:\n",
        "  print(xb)\n",
        "  print(yb)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 87., 135.,  57.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 92.,  87.,  64.],\n",
            "        [ 91.,  87.,  65.],\n",
            "        [ 91.,  88.,  64.]])\n",
            "tensor([[118., 134.],\n",
            "        [ 22.,  37.],\n",
            "        [ 82., 100.],\n",
            "        [ 80., 102.],\n",
            "        [ 81., 101.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7UoMoMLE4js"
      },
      "source": [
        "by comparing the inputs with the batches (xb,yb)create above we can see that the data is shuffle (shuffle=True)\n",
        "\n",
        "in each itrration the dataloader returns one batch of data with the given batch size .If shuffle is set to True ,it shuffle the data before creating batches .Shuffling helps randamize the input to the optimization algorithum .Leading to the fast reduction in the loss \n",
        "\n",
        "the more there is randamization , the faster the model trains "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NomTU2YlGN8r"
      },
      "source": [
        "##nn.Linear \n",
        "instead of initializing the weights & baises manually , we can define the model using nn.Linear class from pyTorch , which does it automatically "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuRstYaEG3XW",
        "outputId": "d712abaa-1630-4044-bf43-b729179e0e07"
      },
      "source": [
        "#define model \n",
        "model=nn.Linear(3,2)#3=inputs(temp,rainfall,humidity)2=output(yeild of apples ,yeild of oranges )\n",
        "print(model.weight)\n",
        "print(model.bias)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.4978, -0.1771,  0.1230],\n",
            "        [ 0.3177, -0.2521,  0.5302]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.1069,  0.5339], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9Mr5kK3dHsB"
      },
      "source": [
        "pytorch model also have a helpfull .paremeters method , which returns a list containing all the weights and baises matrix present in the model .for our linear regression model , we have one weight matrix and one baises matrix  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ug1J785xd9aq",
        "outputId": "4378b53a-a676-43b9-aa8d-f30c2cf09dcf"
      },
      "source": [
        "#parameters\n",
        "list(model.parameters())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.4978, -0.1771,  0.1230],\n",
              "         [ 0.3177, -0.2521,  0.5302]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.1069,  0.5339], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CQzjke5eT3j"
      },
      "source": [
        "we can use the model to genarate pridiction in same way as before "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8LxaMyNelv4",
        "outputId": "9a735a72-3204-4dd5-b0b2-605627cd2eea"
      },
      "source": [
        "#genarate pridiction \n",
        "preds=model(inputs )\n",
        "preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-43.0214,  29.6351],\n",
              "        [-53.1174,  41.1938],\n",
              "        [-60.0084,  25.1451],\n",
              "        [-53.9466,  41.7188],\n",
              "        [-42.8441,  35.3679],\n",
              "        [-43.3422,  30.2050],\n",
              "        [-52.8174,  41.9761],\n",
              "        [-60.3833,  25.9930],\n",
              "        [-53.6259,  41.1490],\n",
              "        [-42.2233,  35.5803],\n",
              "        [-42.7214,  30.4174],\n",
              "        [-53.4382,  41.7637],\n",
              "        [-60.3085,  24.3629],\n",
              "        [-54.5674,  41.5064],\n",
              "        [-42.5233,  34.7981]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zh5x1zC3f6kp"
      },
      "source": [
        "##Loss Function \n",
        "instead of defining loss function  manually we can use the built-in loss function \"mse_loss\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2ZKCZiZf5wk"
      },
      "source": [
        "# importing nn function \n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_LEtW902GtL"
      },
      "source": [
        "the nn.functional  package contains many usefull loss function and several other utilities   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SckxH9l02-4F"
      },
      "source": [
        "#define loss function \n",
        "loss_fn=F.mse_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJUehbel65pC"
      },
      "source": [
        "let's compute the loss for the current prediction of our  model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKLB9wza7Ex4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ec1e671-ff34-4c76-85b3-7f050d7be3cf"
      },
      "source": [
        "loss=loss_fn(model(inputs),targets)\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(11035.3281, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Yo67H5PrAN6"
      },
      "source": [
        "##optimizer\n",
        "instead of manuallly manupalating the models's weights and baises using gradiants, we can use the optimizer optim.SGD (stochastic gradiant decent ).Stochastic indicates that samples are selected in random batches instead of a single group "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5LDNXe2r6Ip"
      },
      "source": [
        "#defining optimizer\n",
        "opt=torch.optim.SGD(model.parameters(),lr=1e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QB1XohH3sbm3"
      },
      "source": [
        "Note that the model.parameters() is passed as an argument to optim.SGD so that the optimizer knows which matrix to be modified during the update step .also we can specify a learning rate that contraols the amount by which the parameters are modified  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqWqNcjDt6gl"
      },
      "source": [
        "## Train the model\n",
        "we are now ready to train the model . We'll follow the same steps to implement gradiant decent \n",
        "\n",
        "*   genarate prediction\n",
        "*   calculate the loss \n",
        "*   compute gradient w.r.t weights and baises \n",
        "*   adjust the weights by substracting a small quantity proportional to gradient \n",
        "*   rest the gradient to zero \n",
        "\n",
        "the only change is that we'll work on batches of data instead of processing the entire  training data  in every itration . Let's define a utility function fit that train the model for a given number of epochs \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpXD29L71iYK"
      },
      "source": [
        "#utility function to train the model \n",
        "def fit (num_epochs, model,loss_fn,opt, train_dl):\n",
        "\n",
        "  #repeat for the given number of epochs \n",
        "  for epoch in range (num_epochs):\n",
        "\n",
        "    #train the batchs of data \n",
        "    for xb, yb in train_dl:\n",
        "\n",
        "      #1 genarate pridiction \n",
        "      pred=model(xb)\n",
        "\n",
        "      #2 calculate the loss \n",
        "      loss=loss_fn(pred,yb)\n",
        "\n",
        "      #3 compute gradiant \n",
        "      loss.backward()\n",
        "\n",
        "      #4 update parameters using gradiant \n",
        "      opt.step()\n",
        "\n",
        "      #5 reset the gradiant to zero\n",
        "      opt.zero_grad()\n",
        "\n",
        "      #6 print the progress\n",
        "      if(epoch+1)  % 10==0:\n",
        "        print(\"Epoch [{},{}] , Loss :{:.4f\", format(epoch+1), num_epochs,loss.item())\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DDWzgEXIQqh"
      },
      "source": [
        "### somethings to note above\n",
        "*   we use the data loader defined earlier to get batches of data for every itration.\n",
        "*   instead of updating parameters(weights & baises) manualy we use opt.step to perform the update and opt.zero_grad to reset the gradiant to zero\n",
        "*    we also add the log statment that prints the loss from the last batch of data for every 10th epoch to track the traning progress . loss.item retures the actual value stored in the loss tensor \n",
        "\n",
        "Let's train the model for 100 epochs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obRoKh8HKLo7",
        "outputId": "8c8229ab-c752-49b4-e893-31db26992df5"
      },
      "source": [
        "fit(100,model,loss_fn,opt,train_dl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [{},{}] , Loss :{:.4f 10 100 262.38519287109375\n",
            "Epoch [{},{}] , Loss :{:.4f 10 100 463.1507263183594\n",
            "Epoch [{},{}] , Loss :{:.4f 10 100 105.70985412597656\n",
            "Epoch [{},{}] , Loss :{:.4f 20 100 67.32218933105469\n",
            "Epoch [{},{}] , Loss :{:.4f 20 100 202.79148864746094\n",
            "Epoch [{},{}] , Loss :{:.4f 20 100 301.6537780761719\n",
            "Epoch [{},{}] , Loss :{:.4f 30 100 118.35737609863281\n",
            "Epoch [{},{}] , Loss :{:.4f 30 100 208.3970184326172\n",
            "Epoch [{},{}] , Loss :{:.4f 30 100 67.3210678100586\n",
            "Epoch [{},{}] , Loss :{:.4f 40 100 95.81165313720703\n",
            "Epoch [{},{}] , Loss :{:.4f 40 100 70.26551818847656\n",
            "Epoch [{},{}] , Loss :{:.4f 40 100 96.84049987792969\n",
            "Epoch [{},{}] , Loss :{:.4f 50 100 69.88969421386719\n",
            "Epoch [{},{}] , Loss :{:.4f 50 100 53.0590705871582\n",
            "Epoch [{},{}] , Loss :{:.4f 50 100 57.57508087158203\n",
            "Epoch [{},{}] , Loss :{:.4f 60 100 38.878204345703125\n",
            "Epoch [{},{}] , Loss :{:.4f 60 100 20.244686126708984\n",
            "Epoch [{},{}] , Loss :{:.4f 60 100 67.06303405761719\n",
            "Epoch [{},{}] , Loss :{:.4f 70 100 42.57476043701172\n",
            "Epoch [{},{}] , Loss :{:.4f 70 100 27.64031410217285\n",
            "Epoch [{},{}] , Loss :{:.4f 70 100 16.712657928466797\n",
            "Epoch [{},{}] , Loss :{:.4f 80 100 10.605116844177246\n",
            "Epoch [{},{}] , Loss :{:.4f 80 100 28.766246795654297\n",
            "Epoch [{},{}] , Loss :{:.4f 80 100 21.38823890686035\n",
            "Epoch [{},{}] , Loss :{:.4f 90 100 6.705696105957031\n",
            "Epoch [{},{}] , Loss :{:.4f 90 100 24.19808006286621\n",
            "Epoch [{},{}] , Loss :{:.4f 90 100 11.828619956970215\n",
            "Epoch [{},{}] , Loss :{:.4f 100 100 8.298823356628418\n",
            "Epoch [{},{}] , Loss :{:.4f 100 100 16.596006393432617\n",
            "Epoch [{},{}] , Loss :{:.4f 100 100 5.524935245513916\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mi_-9r29Kuaq",
        "outputId": "e75a2a43-e90b-4e16-a758-f5366891f5e7"
      },
      "source": [
        "preds=model(inputs)\n",
        "preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 57.6856,  71.7047],\n",
              "        [ 81.9604, 101.0835],\n",
              "        [117.6580, 129.9747],\n",
              "        [ 24.7484,  44.3994],\n",
              "        [ 99.3864, 115.6383],\n",
              "        [ 56.5330,  70.8100],\n",
              "        [ 81.7414, 101.1898],\n",
              "        [117.9404, 130.6281],\n",
              "        [ 25.9010,  45.2941],\n",
              "        [100.3199, 116.6393],\n",
              "        [ 57.4665,  71.8110],\n",
              "        [ 80.8079, 100.1888],\n",
              "        [117.8770, 129.8684],\n",
              "        [ 23.8149,  43.3983],\n",
              "        [100.5389, 116.5330]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vumfjLjHK5gs",
        "outputId": "dcab5337-b2f2-4908-d211-0b791debcc3f"
      },
      "source": [
        "targets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.],\n",
              "        [ 57.,  69.],\n",
              "        [ 80., 102.],\n",
              "        [118., 132.],\n",
              "        [ 21.,  38.],\n",
              "        [104., 118.],\n",
              "        [ 57.,  69.],\n",
              "        [ 82., 100.],\n",
              "        [118., 134.],\n",
              "        [ 20.,  38.],\n",
              "        [102., 120.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIGi7uUJLjGd"
      },
      "source": [
        "indeed ,the prediction are close to the target. we have a trained a resonably good model to pridict crop yeild for apples and oranges by looking at the avgrage temperature , rainfall,and humidity in a reign. we can use this to make pridiction of crop yeild for new regions by passinf a batch of single row of inputs "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NqFW8sLMlPX",
        "outputId": "24d1d709-3546-48ed-f07b-ddc04bae7407"
      },
      "source": [
        "model(torch.tensor([[75,63,44.]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[54.3343, 69.3008]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vd6LAgMuNDmg"
      },
      "source": [
        "the pridicted yeild of apple is 54.33 tons per hector and that of oranges is 69.30 tons per hector "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sxB_uGKNjLC"
      },
      "source": [
        "## Machine Learning vs. Classical Programming\n",
        "\n",
        " we've defined a \"model\" that assumes a specific relationship between the inputs and the outputs, expressed using some unknown parameters (weights & biases). We then show the model some know inputs and outputs and _train_ the model to come up with good values for the unknown parameters. Once trained, the model can be used to compute the outputs for new inputs.\n",
        "\n",
        "This paradigm of programming is known as _machine learning_, where we use data to figure out the relationship between inputs and outputs. _Deep learning_ is a branch of machine learning that uses matrix operations, non-linear activation functions and gradient descent to build and train models. Andrej Karpathy, the director of AI at Tesla Motors, has written a great blog post on this topics, titled [Software 2.0](https://medium.com/@karpathy/software-2-0-a64152b37c35).\n",
        "\n",
        "This picture from book [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python) by Francois Chollet captures the difference between classical programming and machine learning:\n",
        "\n",
        "![](https://i.imgur.com/oJEQe7k.png)\n",
        "\n",
        "Keep this picture in mind as you work through the next few tutorials. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSokLtEKNlV8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}